{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a947286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d48bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in notebook_params notebook, then run that notebook and this cell to update here\n",
    "DO NOT modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "print(\"Basic Parameters: \\n time-series data is in (smooth_dir): {} \\n\"\n",
    "      \" modelling year is (filter_year param): {} (this is first year if season spans two years)\"\n",
    "      .format(basic_config['smooth_dir'], basic_config['filter_yr']))\n",
    "%store -r classification_params\n",
    "\n",
    "print(\"Classification_Params: \\n\" \n",
    "      \" modelling mode is {} \\n\"\n",
    "      \" model_type = {} \\n\"\n",
    "      \" output files are saved to (model_dir): {} \\n\" \n",
    "      \" shared input files are in (main_model_dir): {} \\n\"\n",
    "      \" sample_model = {} \\n feature_model = {} \\n model_name = {} \\n\"\n",
    "      \" the full sample pt file: {} \\n\"\n",
    "      \" the full sample dataframe with the feature model applied: {} \\n\"\n",
    "      \" the subset pt file based on the sample model: {} \\n\"\n",
    "      \" lc_class = {} \\n ranhold = {} \\n impmeth = {}\"\n",
    "      .format(classification_params['model_mode'],classification_params['model_type'],classification_params['model_dir'],\n",
    "              classification_params['main_model_dir'],classification_params['sample_model'],classification_params['feature_model'],\n",
    "              classification_params['model_name'],basic_config['ptfile'],classification_params['samp_pix_vars'],classification_params['samp_pts'],\n",
    "              classification_params['lc_mod'],classification_params['ranhold'],classification_params['impmeth']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e6b2f",
   "metadata": {},
   "source": [
    "#### Set new variables here for temp model testing: -- SKIP if keeping original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set new variables here for temp model testing:\n",
    "feature_model = \"base4NoPoly\"\n",
    "## Sample model options currently: bal400mix1 | bal400mix2 | bal400mix3\n",
    "sample_model = 'base1000'\n",
    "#sample_model = \"bal400mix8\"\n",
    "\n",
    "## The following will set themselves based on the above variables:\n",
    "classification_params['feature_model'] = feature_model\n",
    "classification_params['sample_model'] = sample_model\n",
    "classification_params['model_name'] = '{}_{}'.format(feature_model, sample_model)\n",
    "classification_params['samp_pix_vars'] = '{}/ptsgdb_{}.csv'.format(classification_params['model_dir'],feature_model)\n",
    "classification_params[\"samp_pts\"] = '/home/downspout-cel/paraguay_lc/classification/RF/sample_dfs/{}.csv'.format(sample_model)\n",
    "print('Now working with sample_model: {} \\n New output model will be named: {}'\n",
    "      .format(classification_params['sample_model'],classification_params['model_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d081503-83b0-41d5-9202-2cb1be3cfb28",
   "metadata": {},
   "source": [
    "## Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a567ea-f130-4b2c-8a82-f54243fe28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut=pd.read_csv('../Class_LUT.csv')\n",
    "#print(lut.sort_values('LC_UNQ')[['LC_UNQ','USE_NAME','LC25','LC25_name']])\n",
    "\n",
    "samp_pts = pd.read_csv(classification_params['samp_pts'])\n",
    "print(samp_pts.columns.tolist())\n",
    "#if mod_name == \"base1000\":\n",
    "#    samp_pts.rename(columns = {\"Unnamed: 0\": 'OID_'}, inplace = True)\n",
    "\n",
    "pix_vars = pd.read_csv(classification_params['samp_pix_vars'])\n",
    "#print(pix_vars.columns.tolist())\n",
    "\n",
    "pix_data = samp_pts.merge(pix_vars, left_on='OID_', right_on='OID_', how='inner')\n",
    "print('sample breakdown by LC25 class:')\n",
    "print(pix_data['LC25_name'].value_counts())\n",
    "\n",
    "if classification_params['model_mode'] == 'production':\n",
    "    #pixdf = pix_data.merge(lut, left_on='Class', right_on='USE_NAME', how='left')\n",
    "    pixdf_path = os.path.join(classification_params['model_dir'],\n",
    "                                             'pixdf_{}.csv'.format(classification_params['model_name']))\n",
    "    pd.DataFrame.to_csv(pix_data, pixdf_path)\n",
    "    classification_params[\"pixdf\"] = pixdf_path\n",
    "\n",
    "else:\n",
    "    classification_params[\"pixdf\"] = pix_data\n",
    "    #print(classification_params['pixdf'].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696938fd",
   "metadata": {},
   "source": [
    "## View the look up table\n",
    "These are the different LC_models to group things in classification and to translate between numerical map categories and text labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut=pd.read_csv('../Class_LUT.csv')\n",
    "lut.drop(['Description'], axis=1, inplace=True)\n",
    "\n",
    "print(lut.sort_values('LC_UNQ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2658d",
   "metadata": {},
   "source": [
    "## get sample dataframe:\n",
    " pixdf is the combination of the sample point file and variable stack for those points (pix_vars).\n",
    " This is created in notebooks 6a and 6b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(classification_params['pixdf'])\n",
    "pixdf = pd.read_csv(classification_params['pixdf'])\n",
    "#pixdf = pixdf.dropna(inplace = True)\n",
    "#print(pixdf)\n",
    "#print(pixdf.isnull().any().any())\n",
    "print('sample breakdown by {}:'.format(classification_params['lc_mod']))\n",
    "label_col, new_lut = get_class_col(classification_params['lc_mod'], lut)\n",
    "if '{}_name'.format(label_col) in pixdf.columns:\n",
    "    print(pixdf['{}_name'.format(label_col)].value_counts())\n",
    "else:\n",
    "    pixdf2 = pixdf.merge(new_lut[['USE_NAME','{}'.format(label_col),'{}_name'.format(label_col)]], left_on='Class', right_on='USE_NAME', how='left')\n",
    "    print(pixdf2['{}_name'.format(label_col)].value_counts())\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e7ae8",
   "metadata": {},
   "source": [
    "## create rf model\n",
    "this uses the multiclass RandomForestClassifier method from sklearn.ensemble (code is in ../LUCinSA_helpers/rf.py)\n",
    "\n",
    "To use a different classification model, change 'lc_mod' in the parameters and rerun\n",
    "current models = ('All' | 'trans_cats\" | 'crop_nocrop' | 'crop_nocrop_medcrop' | 'crop_nocrop_medcrop_tree' | 'veg' | 'cropType' or 'single_X' (where X is any unique string in the USE_NAME column) for binary classification of X vs all else) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eca1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf0 = rf_model(classification_params['pixdf'],\n",
    "         classification_params['model_dir'],\n",
    "         classification_params['lc_mod'],\n",
    "         classification_params['impmeth'],\n",
    "         classification_params['ranhold'],\n",
    "         classification_params['model_name'],\n",
    "         lut,     \n",
    "         classification_params['feature_model'],\n",
    "         classification_params['feature_mod_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d87ac",
   "metadata": {},
   "source": [
    "## view confusion matrices\n",
    "Note parameters: (pred_col, obs_col, lut, lc_mod_map, lc_mod_acc, print_cm=False, out_dir=None, model_name=None)\n",
    "To print cm to csv file, change print_cm to True and provide an out_dir and model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note: if running build_weighted_accuracy_table below, these will be printed to file within that.\n",
    "'''\n",
    "\n",
    "cm_cropNoCrop = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'cropNoCrop', \n",
    "                                     print_cm=False, out_dir=classification_params['model_dir'],\n",
    "                                     model_name=classification_params['model_name'])\n",
    "cm_cropType = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'cropType', \n",
    "                                   print_cm=False, out_dir=classification_params['model_dir'],\n",
    "                                   model_name=classification_params['model_name'])\n",
    "cm_veg = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'veg', \n",
    "                              print_cm=False, out_dir=classification_params['model_dir'],\n",
    "                              model_name=classification_params['model_name'])\n",
    "cm_all = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'all', \n",
    "                              print_cm=False, out_dir=classification_params['model_dir'],\n",
    "                              model_name=classification_params['model_name'])\n",
    "#cm_single = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],classification_params['lc_mod'],False,classification_params['model_dir'],None)\n",
    "\n",
    "print(cm_cropNoCrop)\n",
    "#print(cm_cropType)\n",
    "#print(cm_veg)\n",
    "#print(cm_all)\n",
    "#print(cm_single)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071eca7",
   "metadata": {},
   "source": [
    "## view variable importance\n",
    "this can be computed via Impurity or Permutation method (see sklearn docs)  by setting impmeth in rf_model\n",
    "The full list is stored in the model directory for further manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac864cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_path = os.path.join(classification_params['model_dir'],'VarImportance_{}.csv'.format(classification_params['model_name']))\n",
    "var_imp = pd.read_csv(var_imp_path, names=['var','imp'], header=None)\n",
    "## view 10 most important variables:\n",
    "var_imp.sort_values('imp', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6215c5",
   "metadata": {},
   "source": [
    "## Build weighted accuracy matrix for model selection / optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b824df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = classification_params['model_name']\n",
    "out_dir = os.path.join(classification_params['local_dir'],'cms')\n",
    "wacc = build_weighted_accuracy_table(out_dir,model_name,rf0[1],classification_params[\"pixdf\"],lut)\n",
    "print(wacc.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f6bff-e3ef-48df-b9ce-f7960d02e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this to remove certain rows from the dfs that you do not want anymore\n",
    "\n",
    "\"\"\"\n",
    "types = [\"cropNoCrop\", \"cropType\", \"veg\", \"all\"]\n",
    "\n",
    "delrow = 0\n",
    "for i in types:\n",
    "    mat = pd.read_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/{}_metrics.csv\".format(i), index_col = 0)\n",
    "    \n",
    "    mat = mat.drop([delrow])\n",
    "    print(mat)\n",
    "    mat.to_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/{}_metrics.csv\".format(i))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86fb73-5c9b-4e74-9b73-f8fc823fc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this to remove certain rows from the df that you do not want anymore\n",
    "\n",
    "\"\"\"\n",
    "delrow = 16\n",
    "mat = pd.read_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/overall_metrics.csv\", index_col = 0)\n",
    "mat = mat.drop([delrow])\n",
    "print(mat)\n",
    "mat.to_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/overall_metrics.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c30f8-b1d5-44e8-a856-5e3e4a897b7a",
   "metadata": {},
   "source": [
    "## Make some tables that organize the data cleanly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777bbdd-17e3-4bd6-bbd4-e53e3fdf0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Organize all of the models that exclude poly_pred variables\n",
    "\n",
    "key_word = \"Max_no_pp_\"\n",
    "model_name = classification_params['model_name']\n",
    "\n",
    "stored = pd.read_csv(os.path.join(out_dir,'metrics','overall_metrics.csv'), index_col = 0)\n",
    "tab = []\n",
    "for i in stored.iterrows():\n",
    "    if i[1][\"Model\"] == \"Max_{}\".format(model_name):\n",
    "        tab.append(i[1])\n",
    "    if i[1][\"Model\"].startswith(key_word):\n",
    "        tab.append(i[1])\n",
    "\n",
    "tab = pd.DataFrame(tab)\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942115ee-4d19-4a6f-ac58-774c24bedd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae950239-e398-4523-abf3-1dd02ea6c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## some cool graphs of the data you could have compiled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a9d11e",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:\n",
    "(these two cells should be last in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35471d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "### comment out above line and run this cell to print output as html\n",
    "\n",
    "out_name = str(basic_config['country']+'6c_RandomFoest_ModelComparisons'+'_model'+str(classification_params['model_name'])+'basic_config['filter_yr'])\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --ExecutePreprocessor.store_widget_state=True --output=$out_name 6b_RandomFoest_ModelComparisons.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075d3f8-981c-42e2-aa5b-9fd20e2cf664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
