{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a947286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d48bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in notebook_params notebook, then run that notebook and this cell to update here\n",
    "DO NOT modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "print(\"Basic Parameters: \\n time-series data is in (smooth_dir): {} \\n\"\n",
    "      \" modelling year is (filter_year param): {} (this is first year if season spans two years)\"\n",
    "      .format(basic_config['smooth_dir'], basic_config['filter_yr']))\n",
    "%store -r classification_params\n",
    "\n",
    "print(\"Classification_Params: \\n\" \n",
    "      \" modelling mode is {} \\n\"\n",
    "      \" model_type = {} \\n\"\n",
    "      \" output files are saved to (model_dir): {} \\n\" \n",
    "      \" shared input files are in (main_model_dir): {} \\n\"\n",
    "      \" sample_model = {} \\n feature_model = {} \\n model_name = {} \\n\"\n",
    "      \" the full sample pt file: {} \\n\"\n",
    "      \" the full sample dataframe with the feature model applied: {} \\n\"\n",
    "      \" the subset pt file based on the sample model: {} \\n\"\n",
    "      \" lc_class = {} \\n ranhold = {} \\n impmeth = {}\"\n",
    "      .format(classification_params['model_mode'],classification_params['model_type'],classification_params['model_dir'],\n",
    "              classification_params['main_model_dir'],classification_params['sample_model'],classification_params['feature_model'],\n",
    "              classification_params['model_name'],basic_config['ptfile'],classification_params['samp_pix_vars'],classification_params['samp_pts'],\n",
    "              classification_params['lc_mod'],classification_params['ranhold'],classification_params['impmeth']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e6b2f",
   "metadata": {},
   "source": [
    "#### Set new variables here for temp model testing: -- SKIP if keeping original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set new variables here for temp model testing:\n",
    "feature_model = \"Max\"\n",
    "## Sample model options currently: bal400mix1 | bal400mix2 | bal400mix3\n",
    "sample_model = \"bal400mix3\"\n",
    "\n",
    "## The following will set themselves based on the above variables:\n",
    "classification_params['feature_model'] = feature_model\n",
    "classification_params['sample_model'] = sample_model\n",
    "classification_params['model_name'] = '{}_{}'.format(feature_model, sample_model)\n",
    "classification_params['samp_pix_vars'] = '{}/ptsgdb_{}.csv'.format(classification_params['model_dir'],feature_model)\n",
    "classification_params[\"samp_pts\"] = '/home/downspout-cel/paraguay_lc/classification/RF/sample_dfs/{}.csv'.format(sample_model)\n",
    "print('Now working with sample_model: {} \\n New output model will be named: {}'\n",
    "      .format(classification_params['sample_model'],classification_params['model_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d081503-83b0-41d5-9202-2cb1be3cfb28",
   "metadata": {},
   "source": [
    "## Merge dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a567ea-f130-4b2c-8a82-f54243fe28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut=pd.read_csv('../Class_LUT.csv')\n",
    "#print(lut.sort_values('LC_UNQ')[['LC_UNQ','USE_NAME','LC25','LC25_name']])\n",
    "\n",
    "samp_pts = pd.read_csv(classification_params['samp_pts'])\n",
    "print(samp_pts.columns.tolist())\n",
    "#if mod_name == \"base1000\":\n",
    "#    samp_pts.rename(columns = {\"Unnamed: 0\": 'OID_'}, inplace = True)\n",
    "\n",
    "pix_vars = pd.read_csv(classification_params['samp_pix_vars'])\n",
    "#print(pix_vars.columns.tolist())\n",
    "\n",
    "pix_data = samp_pts.merge(pix_vars, left_on='OID_', right_on='OID_', how='inner')\n",
    "print('sample breakdown by LC25 class:')\n",
    "print(pix_data['LC25_name'].value_counts())\n",
    "\n",
    "#pixdf = pix_data.merge(lut, left_on='Class', right_on='USE_NAME', how='left')\n",
    "\n",
    "classification_params[\"pixdf\"] = pix_data\n",
    "#print(classification_params['pixdf'].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696938fd",
   "metadata": {},
   "source": [
    "## View the look up table\n",
    "These are the different LC_models to group things in classification and to translate between numerical map categories and text labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut=pd.read_csv('../Class_LUT.csv')\n",
    "lut.drop(['Description'], axis=1, inplace=True)\n",
    "\n",
    "print(lut.sort_values('LC_UNQ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2658d",
   "metadata": {},
   "source": [
    "## get sample dataframe:\n",
    " pixdf is the combination of the sample point file and variable stack for those points (pix_vars).\n",
    " This is created in notebooks 6a and 6b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(classification_params['pixdf'])\n",
    "pixdf = pd.read_csv(classification_params['pixdf'])\n",
    "#pixdf = pixdf.dropna(inplace = True)\n",
    "#print(pixdf)\n",
    "#print(pixdf.isnull().any().any())\n",
    "print('sample breakdown by {}:'.format(classification_params['lc_mod']))\n",
    "label_col, new_lut = get_class_col(classification_params['lc_mod'], lut)\n",
    "if '{}_name'.format(label_col) in pixdf.columns:\n",
    "    print(pixdf['{}_name'.format(label_col)].value_counts())\n",
    "else:\n",
    "    pixdf2 = pixdf.merge(new_lut[['USE_NAME','{}'.format(label_col),'{}_name'.format(label_col)]], left_on='Class', right_on='USE_NAME', how='left')\n",
    "    print(pixdf2['{}_name'.format(label_col)].value_counts())\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e7ae8",
   "metadata": {},
   "source": [
    "## create rf model\n",
    "this uses the multiclass RandomForestClassifier method from sklearn.ensemble (code is in ../LUCinSA_helpers/rf.py)\n",
    "\n",
    "To use a different classification model, change 'lc_mod' in the parameters and rerun\n",
    "current models = ('All' | 'trans_cats\" | 'crop_nocrop' | 'crop_nocrop_medcrop' | 'crop_nocrop_medcrop_tree' | 'veg' | 'cropType' or 'single_X' (where X is any unique string in the USE_NAME column) for binary classification of X vs all else) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eca1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf0 = rf_model(classification_params['pixdf'],\n",
    "         classification_params['model_dir'],\n",
    "         classification_params['lc_mod'],\n",
    "         classification_params['impmeth'],\n",
    "         classification_params['ranhold'],\n",
    "         classification_params['model_name'],\n",
    "         lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d87ac",
   "metadata": {},
   "source": [
    "## view confusion matrices\n",
    "Note parameters: (pred_col, obs_col, lut, lc_mod_map, lc_mod_acc, print_cm=False, out_dir=None, model_name=None)\n",
    "To print cm to csv file, change print_cm to True and provide an out_dir and model_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(classification_params['local_dir']/'cms')\n",
    "\n",
    "cm_cropNoCrop = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'cropNoCrop',True, os.path.join(out_dir,'cropNoCrop_cms'),classification_params['model_name'])\n",
    "cm_cropType = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'cropType',True,os.path.join(out_dir,'cropType_cms'),classification_params['model_name'])\n",
    "cm_veg = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'veg',True,os.path.join(out_dir,'veg_cms'),classification_params['model_name'])\n",
    "cm_all = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],'all',True,os.path.join(out_dir,'all_cms'),classification_params['model_name'])\n",
    "#cm_single = get_confusion_matrix(rf0[1]['pred'],rf0[1]['label'],lut,classification_params['lc_mod'],classification_params['lc_mod'],False,classification_params['local_model_dir'],None)\n",
    "\n",
    "print(cm_cropNoCrop)\n",
    "#print(cm_cropType)\n",
    "#print(cm_veg)\n",
    "#print(cm_all)\n",
    "#print(cm_single)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071eca7",
   "metadata": {},
   "source": [
    "## view variable importance\n",
    "this can be computed via Impurity or Permutation method (see sklearn docs)  by setting impmeth in rf_model\n",
    "The full list is stored in the model directory for further manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac864cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_path = os.path.join(classification_params['model_dir'],'VarImportance_{}.csv'.format(classification_params['model_name']))\n",
    "var_imp = pd.read_csv(var_imp_path, names=['var','imp'], header=None)\n",
    "## view 10 most important variables:\n",
    "var_imp.sort_values('imp', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952f86c-f763-49b6-9a13-0f6bd8fa4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smallholder(rf_mod, one = False, half = False):\n",
    "    rf_mod = pd.DataFrame(rf_mod)\n",
    "    if one == True: #decide if you want to do 1ha or halfha\n",
    "        smalls = rf_mod.loc[rf_mod['smalls_1ha'] == 1]\n",
    "        print('There are {} 1ha smallholder samples in the holdout.'.format(smalls.shape[0]))\n",
    "    elif half == True: \n",
    "        smalls = rf_mod.loc[rf_mod['smalls_halfha'] == 1]\n",
    "        print('There are {} half-ha smallholder samples in the holdout.'.format(smalls.shape[0]))\n",
    "    \n",
    "    return smalls\n",
    "\n",
    "def small_acc(rf_mod, one = False, half = False):\n",
    "    if one == True:\n",
    "        one_ha = get_smallholder(rf_mod[1], one = True) # df for 1_ha smallholder ag\n",
    "        one_ha_cropNoCrop = get_confusion_matrix(one_ha['pred'], one_ha['label'],lut,classification_params['lc_mod'],'cropNoCrop',False,classification_params['model_dir'],None)\n",
    "        return one_ha_cropNoCrop.head(1)[\"crop\"]/one_ha_cropNoCrop.head(1)[\"All\"]\n",
    "    \n",
    "    if half == True:\n",
    "        half_ha = get_smallholder(rf_mod[1], half = True) # df for half_ha smallholder ag\n",
    "        half_ha_cropNoCrop = get_confusion_matrix(half_ha['pred'], half_ha['label'],lut,classification_params['lc_mod'],'cropNoCrop',False,classification_params['model_dir'],None)\n",
    "        return half_ha_cropNoCrop.head(1)[\"crop\"]/half_ha_cropNoCrop.head(1)[\"All\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9754b-2120-453d-9a7a-97c063df2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "## take the cms and find take the averages of the UAs and PAs\n",
    "'''\n",
    "# only run this section once to create the csvs and then comment out\n",
    "feature_model = classification_params['feature_model']\n",
    "sample_model = classification_params['sample_model']\n",
    "model_name = classification_params['model_name']\n",
    "out_dir = os.path.join(classification_params['local_dir'],'cms')\n",
    "\n",
    "cropNoCrop_metrics = pd.DataFrame({\"Model\": [\"{}\".format(model_name)],\n",
    "                             \"UA\": [wave(os.path.join(out_dir,'cropNoCrop_cms','{}_cropNoCrop.csv'.format(model_name)), uacc = True)],\n",
    "                             \"PA\": [wave(os.path.join(out_dir,'cropNoCrop_cms','{}_cropNoCrop.csv'.format(model_name)), pacc = True)],\n",
    "                             \"1_ha\": [small_acc(rf0, one = True)[0]], #create a new function that uses the smallholder rf outputs in a useful manner\n",
    "                             \"half_ha\": [small_acc(rf0, half = True)[0]],\n",
    "                             \"No. of Obs.\": [len(classification_params[\"pixdf\"][\"LC25_name\"])]})\n",
    "cropType_metrics = pd.DataFrame({\"Model\": [\"{}\".format(model_name)],\n",
    "                             \"UA\": [wave(os.path.join(out_dir,'cropType_cms','{}_cropType.csv'.format(model_name)), uacc = True)],\n",
    "                             \"PA\": [wave(os.path.join(out_dir,'cropType_cms','{}_cropType.csv'.format(model_name)), pacc = True)],\n",
    "                             \"No. of Obs.\": [len(classification_params[\"pixdf\"][\"LC25_name\"])]})\n",
    "veg_metrics = pd.DataFrame({\"Model\": [\"{}\".format(model_name)],\n",
    "                             \"UA\": [wave(os.path.join(out_dir,'veg_cms','{}_veg.csv'.format(model_name)), uacc = True)],\n",
    "                             \"PA\": [wave(os.path.join(out_dir,'veg_cms','{}_veg.csv'.format(model_name)), pacc = True)],\n",
    "                             \"No. of Obs.\": [len(classification_params[\"pixdf\"][\"LC25_name\"])]})\n",
    "all_metrics = pd.DataFrame({\"Model\": [\"{}\".format(model_name)],\n",
    "                             \"UA\": [wave(os.path.join(out_dir,'all_cms','{}_all.csv'.format(model_name)), uacc = True)],\n",
    "                             \"PA\": [wave(os.path.join(out_dir,'all_cms','{}_all.csv'.format(model_name)), pacc = True)],\n",
    "                             \"No. of Obs.\": [len(classification_params[\"pixdf\"][\"LC25_name\"])]})\n",
    "\n",
    "print(cropNoCrop_metrics)\n",
    "print(cropType_metrics)\n",
    "print(veg_metrics)\n",
    "print(all_metrics)\n",
    "\n",
    "types = [\"cropNoCrop\", \"cropType\", \"veg\", \"all\"] \n",
    "matrics = [cropNoCrop_metrics, cropType_metrics, veg_metrics, all_metrics]\n",
    "\n",
    "#saves the cms to the /testing/metrics folder\n",
    "for idx, i in enumerate(types):\n",
    "    matrics[idx].to_csv(os.path.join(out_dir,'metrics','{}_metrics.csv'.format(i)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d883f-f948-46be-b4f1-a0e62d29616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csvs and add a new row with the new data\n",
    "\n",
    "def new_wave(cm_path, stored_path, model_name):\n",
    "    stored = pd.read_csv(stored_path, index_col = 0)\n",
    "    new_data = pd.DataFrame({\"Model\": [model_name],\n",
    "                             \"UA\": [wave(cm_path, uacc = True)],\n",
    "                             \"PA\": [wave(cm_path, pacc = True)],\n",
    "                             \"1_ha\": [small_acc(rf0, one = True)[0]],\n",
    "                             \"half_ha\": [small_acc(rf0, half = True)[0]],\n",
    "                             \"No. of Obs.\": [len(classification_params[\"pixdf\"][\"LC25_name\"])]})\n",
    "    #print(stored.reset_index(drop=True))\n",
    "    #print(new_data.reset_index(drop=True))\n",
    "    stored = pd.concat([stored.reset_index(drop = True), new_data.reset_index(drop = True)], ignore_index = True)\n",
    "    return stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf4982-839d-46fb-9b3c-0697c705a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(classification_params['local_dir'],'cms')\n",
    "types = [\"cropNoCrop\", \"cropType\", \"veg\", \"all\"]\n",
    "mats = [cm_cropNoCrop, cm_cropType, cm_veg, cm_all]\n",
    "\n",
    "#updates the metric csvs in /testing/metrics folder\n",
    "for idx, i in enumerate(types):\n",
    "    mats[idx] = new_wave(os.path.join(out_dir,'{}_cms'.format(i),'{}_{}.csv'.format(classification_params['model_name'], i)), \n",
    "                os.path.join(out_dir,'metrics','{}_metrics.csv'.format(i)),classification_params['model_name'])\n",
    "    mats[idx].to_csv(os.path.join(out_dir,'metrics','{}_metrics.csv'.format(i)))\n",
    "    print(mats[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f6bff-e3ef-48df-b9ce-f7960d02e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this to remove certain rows from the dfs that you do not want anymore\n",
    "\n",
    "\"\"\"\n",
    "types = [\"cropNoCrop\", \"cropType\", \"veg\", \"all\"]\n",
    "\n",
    "delrow = 0\n",
    "for i in types:\n",
    "    mat = pd.read_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/{}_metrics.csv\".format(i), index_col = 0)\n",
    "    \n",
    "    mat = mat.drop([delrow])\n",
    "    print(mat)\n",
    "    mat.to_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/{}_metrics.csv\".format(i))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbf490-2c7b-4c04-9762-ebd9b24af303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_wave(cnc_metrics, ct_path, model_name):\n",
    "    \n",
    "    # iterate through rows of the CNC_metrics dataframe\n",
    "    cnc = pd.read_csv(cnc_metrics, index_col = 0)\n",
    "    cnc_partial = cnc[cnc[\"Model\"] == model_name]\n",
    "\n",
    "    # now deal with the CT matrix\n",
    "    ct = pd.read_csv(ct_path, index_col = 0)\n",
    "    ct_partial = [wave(ct_path, uacc = True, weights = \"CT\"), wave(ct_path, pacc = True, weights = \"CT\")]\n",
    "    \n",
    "    cnc_partial = [cnc_partial[\"UA\"], cnc_partial[\"PA\"], cnc_partial[\"1_ha\"], cnc_partial[\"half_ha\"]]\n",
    "    #print(cnc_partial)\n",
    "    #print(ct_partial)\n",
    "\n",
    "    overall_metrics = pd.DataFrame({\"Model\": [\"{}\".format(model_name)],\n",
    "                             \"UA\": [(2 * cnc_partial[0] + ct_partial[0])/3],\n",
    "                             \"PA\": [(2 * cnc_partial[1] + ct_partial[1])/3],\n",
    "                             \"1_ha\": [cnc_partial[2]],\n",
    "                             \"half_ha\": [cnc_partial[3]],\n",
    "                             \"No. of Obs.\": [len(classification_params[\"pixdf\"][\"LC25_name\"])]})\n",
    "    return overall_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02f429-7c10-470e-8951-055a5d2975a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(classification_params['local_dir'],'cms')\n",
    "print(overall_wave(os.path.join(out_dir,'metrics','cropNoCrop_metrics.csv'), \n",
    "                        os.path.join(out_dir,'cropType_cms','{}_cropType.csv'.format(classification_params['model_name'])), \n",
    "                        classification_params['model_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a3d86-576c-4878-8ced-314cfe25a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the baseline for the new overall metrics, once again comment this code out after running it for the first time\n",
    "'''\n",
    "overall = overall_wave(os.path.join(out_dir,'metrics','cropNoCrop_metrics.csv'), \n",
    "             os.path.join(out_dir,'cropType_cms','{}_cropType.csv'.format(classification_params['model_name'])),\n",
    "                       classification_params['model_name'])\n",
    "overall.to_csv(os.path.join(out_dir,'metrics','overall_metrics.csv'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844285e-4796-408d-963d-233a5a7a063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add new rows to the overall_metrics csv\n",
    "\n",
    "stored = pd.read_csv(os.path.join(out_dir,'metrics','overall_metrics.csv'), index_col = 0)\n",
    "new_data = overall_wave(os.path.join(out_dir,'metrics','cropNoCrop_metrics.csv'), \n",
    "                        os.path.join(out_dir,'cropType_cms','{}_cropType.csv'.format(classification_params['model_name'])), \n",
    "                       classification_params['model_name'])\n",
    "#print(stored.reset_index(drop=True))\n",
    "#print(new_data.reset_index(drop=True))\n",
    "stored = pd.concat([stored.reset_index(drop = True), new_data.reset_index(drop = True)], ignore_index = True)\n",
    "print(stored)\n",
    "stored.to_csv(os.path.join(out_dir,'metrics','overall_metrics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86fb73-5c9b-4e74-9b73-f8fc823fc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this to remove certain rows from the df that you do not want anymore\n",
    "\n",
    "\"\"\"\n",
    "delrow = 16\n",
    "mat = pd.read_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/overall_metrics.csv\", index_col = 0)\n",
    "mat = mat.drop([delrow])\n",
    "print(mat)\n",
    "mat.to_csv(\"/home/ryanashraf/LUCinSA_helpers/testing/metrics/overall_metrics.csv\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c30f8-b1d5-44e8-a856-5e3e4a897b7a",
   "metadata": {},
   "source": [
    "## Make some tables that organize the data cleanly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777bbdd-17e3-4bd6-bbd4-e53e3fdf0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Organize all of the models that exclude poly_pred variables\n",
    "\n",
    "key_word = \"Max_no_pp_\"\n",
    "model_name = classification_params['model_name']\n",
    "\n",
    "stored = pd.read_csv(os.path.join(out_dir,'metrics','overall_metrics.csv'), index_col = 0)\n",
    "tab = []\n",
    "for i in stored.iterrows():\n",
    "    if i[1][\"Model\"] == \"Max_{}\".format(model_name):\n",
    "        tab.append(i[1])\n",
    "    if i[1][\"Model\"].startswith(key_word):\n",
    "        tab.append(i[1])\n",
    "\n",
    "tab = pd.DataFrame(tab)\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942115ee-4d19-4a6f-ac58-774c24bedd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae950239-e398-4523-abf3-1dd02ea6c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## some cool graphs of the data you could have compiled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a9d11e",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:\n",
    "(these two cells should be last in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35471d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "### comment out above line and run this cell to print output as html\n",
    "\n",
    "out_name = str(basic_config['country']+'6c_RandomFoest_ModelComparisons'+'_model'+str(classification_params['model_name'])+'basic_config['filter_yr'])\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --ExecutePreprocessor.store_widget_state=True --output=$out_name 6b_RandomFoest_ModelComparisons.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075d3f8-981c-42e2-aa5b-9fd20e2cf664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
