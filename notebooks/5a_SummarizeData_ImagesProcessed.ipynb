{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ee4134",
   "metadata": {},
   "source": [
    "# Summary of images processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ffa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from file_checks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in Notebook_settings notebook, then run that notebook and this cell to update here\n",
    "DO not modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "print(\"Basic Parameters: \\n raw_dir = {} \\n smooth_dir = {} \\n local_dir = {} \\n yr_range = {} \\n today = {}\"\n",
    "      .format(basic_config['raw_dir'],basic_config['smooth_dir'],basic_config['local_dir'],basic_config['yr_range'],basic_config['today']))\n",
    "print(\"spec_indices = {} \\n image_summary_path = {} \\n dl_db_path = {} \\n status_db_path = {}\"\n",
    "      .format(basic_config['spec_indices'],basic_config['image_summary_path'],basic_config['dl_db_path'],basic_config['status_db_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get all files processed in brdf directory across all processed cells:\n",
    "all_images = pd.read_csv(Path(basic_config['image_summary_path']),index_col=[0])\n",
    "all_images.groupby(['yr','sensor']).size().unstack().plot(kind='bar', stacked=True, figsize=(20, 5),\n",
    "            title=('Images processed for {}'.format(basic_config['country'])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "used = all_images[all_images['quality']=='image_used']\n",
    "not_used = all_images[all_images['quality']=='low_quality']\n",
    "print('of the {} images ingested, {} were used in the final map product and {} were excluded due to quality issues'.format(len(used)+len(not_used),len(used),len(not_used)))\n",
    "all_images.groupby(['yr','quality']).size().unstack().plot(color=['black','white'], kind='bar', stacked=True, edgecolor = 'black', figsize=(20, 5),\n",
    "            title=('Image processing results for {}'.format(basic_config['country'])));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15132bd1",
   "metadata": {},
   "source": [
    "### To create / refresh list of processed images\n",
    "Note this can take ~15 min. Can be run from commandline/bash as 'summarize_images_multicell' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to print new `AllFileList.csv' to local directory:\n",
    "#all_files = print_files_in_multiple_directories(basic_config['raw_dir'],\"brdf\",'.nc',print_list=True,out_dir=basic_config['local_dir'])\n",
    "## or uncomment this to create all_files in memory only (to use for quick/partial checks):\n",
    "#all_files = print_files_in_multiple_directories(basic_config['raw_dir'],\"brdf\",'.nc',print_list=False,out_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28981214",
   "metadata": {},
   "source": [
    "## To check all processed cells for missing files at download:\n",
    "Note cell_processing_dl.csv is updated whenever check_log_files_dl.job is run\n",
    "If this gets corrupted (e.g. if the script is run when there is no memory to save), it can be recreated by deleting the corrupted script and moving all of the dl logs from the arcihve folder to the run directory and running check_log_files_dl.job again. If multiple users have downloaded files, each must do this for it to be accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_db = pd.read_csv(Path(basic_config['dl_db_path']),index_col=[0])\n",
    "dl_fix = dl_db[(dl_db['dl_fix_now']!='[]') & (pd.notnull(dl_db['dl_fix_now']))]\n",
    "print(dl_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1689f85b",
   "metadata": {},
   "source": [
    "## update full processing status db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189df5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: this takes a long time from here, but runs fast on command line\n",
    "#update_cell_status_db(basic_config['status_db_path'], 'All', basic_config['raw_dir'], basic_config['smooth_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3293d",
   "metadata": {},
   "source": [
    "## Get full processing status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_db = pd.read_csv(basic_config['status_db_path'],index_col=[0])\n",
    "post_db.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c1576",
   "metadata": {},
   "source": [
    "## Get missing processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells without brdf processing yet (but with downloads)\n",
    "no_brdf = post_db[post_db['num_brdf']!='brdf step not complete']\n",
    "no_brdf.sort_index(inplace=True)\n",
    "print('these cells are missing brdf files')\n",
    "list(no_brdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750323fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells without coreg processing yet (but with brdfs)\n",
    "yes_brdf = post_db[post_db['num_brdf']=='brdf step not complete']\n",
    "no_coreg = yes_brdf[yes_brdf['num_coreged']=='coreg step not complete']\n",
    "no_coreg.sort_index(inplace=True)       \n",
    "print('these cells have not completed coreg (but have brdfs)')\n",
    "list(no_coreg.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fec9ab",
   "metadata": {},
   "source": [
    "##  Get cells with all 6 ts indices complete for (YYYY-YYYY) e.g. 2000-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975321fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_db_path = basic_config['status_db_path']\n",
    "out_path = os.path.join(basic_config['local_dir'],'Cells_with_{}_indices.csv'.format(len(basic_config['spec_indices'])))\n",
    "post_db = pd.read_csv(Path(status_db_path),index_col=[0])\n",
    "ts = [col for col in post_db.columns if 'index' in col]\n",
    "for i in ts:\n",
    "    post_db[f'check_{i}'] = post_db.apply(lambda x: 1 if (isinstance(x[i], str) and \n",
    "                                                            int(x[i].split('-')[0]) <= basic_config['yr_range'][0] and\n",
    "                                                            int(x[i].split('-')[1]) >= basic_config['yr_range'][1])\n",
    "                                          else 0, axis=1)\n",
    "ts_checked = [col for col in post_db.columns if 'check_index' in col]\n",
    "ts_sum = post_db[post_db.columns.intersection(ts_checked)].sum(axis=1)\n",
    "ts_good = ts_sum[ts_sum >=len(basic_config['spec_indices'])]\n",
    "ts_good.to_csv(out_path) \n",
    "print('{} cells have at least {} indices from {} to {}'.format(len(ts_good),len(basic_config['spec_indices']),basic_config['yr_range'][0],basic_config['yr_range'][1]))\n",
    "print('list is printed to {}'.format(out_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70272fdb",
   "metadata": {},
   "source": [
    "## get cells with a specific index (e.g. evi2) run but incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_db = pd.read_csv(basic_config['status_db_path'],index_col=[0])\n",
    "i = basic_config['spec_index']\n",
    "out_path = os.path.join(basic_config['local_dir'],'Cells_with_{}_index_started_but_incomplete.csv'.format(basic_config['spec_index']))\n",
    "post_db_evi = post_db[post_db['index_{}'.format(i)].notnull()]\n",
    "post_db_evi['stat'] = post_db_evi.apply(lambda x: 0 if (int(x['index_{}'.format(i)].split('-')[0]) > basic_config['yr_range'][0] or\n",
    "                                                            int(x['index_{}'.format(i)].split('-')[1]) < basic_config['yr_range'][1])\n",
    "                                          else 1, axis=1)\n",
    "post_db_incomplete = post_db_evi.loc[post_db_evi['stat']==0]\n",
    "incomplete = post_db_incomplete['index_{}'.format(i)]\n",
    "incomplete.to_csv(out_path) \n",
    "print('list of incomplete {} indices is printed to {}'.format(i,out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac736f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_files_in_multiple_directories(basic_config['raw_dir'],'comp','base4Poly6_2021_stack.tif',print_list=False,out_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a7249",
   "metadata": {},
   "source": [
    "### Total number of scenes ingested\n",
    "Note that a single Lansdat image is broken into ~80 grid cell images (A typical Landsat Scene = 31,000 km2 170 km x 185 km -- our grid cells are 400 km2), so images ingested needs to be divided by 80 to get an estimate of the number of actual Landsat / Sentinel scenes ingested. Method above takes a little longer (~15 min), but is much more precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373faeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_ingested_2022 = post_db['images_ingested_2022'].sum()\n",
    "images_ingested = [col for col in post_db.columns if 'images_ingested' in col and 'All' not in col]\n",
    "post_db['images_ingested_All'] = post_db[images_ingested].sum(axis=1)\n",
    "num_images_ingested = post_db['images_ingested_All'].sum()\n",
    "print('About {} images ingested in total for 2022 single-year product'.format(num_images_ingested_2022 // 80))\n",
    "print('About {} images ingested in total 2000-2022 product'.format(num_images_ingested // 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c08e8",
   "metadata": {},
   "source": [
    "### Total number of scenes used \n",
    "#### Excludes scenes not coregistered or not used for other data quality issues\n",
    "Note comment about cells vs. images above. Method above takes a little longer (~15 min), but is much more precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_used_2022 = post_db['images_used_2022'].sum()\n",
    "images_used = [col for col in post_db.columns if 'images_used' in col and 'All' not in col]\n",
    "post_db['images_used_All'] = post_db[images_used].sum(axis=1)\n",
    "num_images_used = post_db['images_used_All'].sum()\n",
    "print('About {} images used in total for 2022 single-year product'.format(num_images_used_2022 // 80))\n",
    "print('About {} images used in final map product for 2000-2022'.format(num_images_used // 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_files.groupby(['yr','sensor']).size().unstack().plot(kind='bar', stacked=True, figsize=(20, 5),\n",
    "            title=('Images processed for {}'.format(basic_config['country'])));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d1d709",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf679d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to print output as html\n",
    "\n",
    "out_name = str(basic_config['country']+'5a_ImagesProcessed_'+basic_config['today'])\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --output=$out_name 5a_SummarizeData_ImagesProcessed.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d4d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
