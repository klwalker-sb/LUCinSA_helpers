{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d941c9",
   "metadata": {},
   "source": [
    "# Get cell processing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a56fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import pickle\n",
    "from shapely.geometry import box\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from file_checks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in notebook_params notebook, then run that notebook and this cell to update here\n",
    "DO NOT modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "print(\"basic parameters: \\n brdf_dir = {} \\n grid_cell = {} \\n index_dir = {} \\n local_dir = {}\"\n",
    "      .format(basic_config['brdf_dir'],basic_config['grid_cell'],basic_config['index_dir'],basic_config['local_dir']))\n",
    "print(\"\\n image_type = {}\".format(basic_config['image_type']))\n",
    "%store -r single_output_params\n",
    "print(\"single_output_params: \\n map_years = {}\".format(single_output_params['map_years']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to fix an old problem. Can probably delete now.\n",
    "for cellid in range(3027):\n",
    "    processing_info_path = Path('{}/{:06d}/processing.info'.format(basic_config['raw_dir'],cellid))\n",
    "    landsat_path = Path('{}/{:06d}/landsat'.format(basic_onfig['raw_dir'],cellid))\n",
    "    sentinel2_path = Path('{}/{:06d}/sentinel2'.format(basicConfig['raw_dir'],cellid))\n",
    "    brdf_path = Path('{}/{:06d}/brdf'.format(basicConfig['raw_dir'],cellid))\n",
    "\n",
    "    print('processing {}...'.format(cellid))\n",
    "    if not os.path.exists(landsat_path):\n",
    "        continue\n",
    "    if processing_info_path.is_file():\n",
    "        reconstructed_dbs = []\n",
    "        deleted_dbs = []\n",
    "        processing_db = pd.read_pickle(processing_info_path)\n",
    "        if 'shift_x' in processing_db:\n",
    "            print ('already has db with shift x')\n",
    "            if len(processing_db['brdf_id'].unique()) < 10:\n",
    "                print('this db was created without unique brdf ids')\n",
    "                processing_db.drop(['brdf','bandpass','brdf_error','brdf_id','coreg','shift_x','shift_y','coreg_error'], axis=1, inplace=True)\n",
    "                pd.to_pickle(processing_db, processing_info_path)\n",
    "                reconstructed_dbs.append(cellid)\n",
    "        elif 'numpix' in processing_db and 'bdrf_id' in processing_db:\n",
    "            if len(processing_db['brdf_id'].unique()) < 10:\n",
    "                print('this db was created without unique brdf ids')\n",
    "                processing_db.drop(['brdf','bandpass','brdf_error','brdf_id'], axis=1, inplace=True)\n",
    "                pd.to_pickle(processing_db, processing_info_path)\n",
    "                reconstructed_dbs.append(cellid)\n",
    "        elif 'numpix' not in processing_db:\n",
    "            print('deleting existing db')\n",
    "            processing_info_path.unlink()\n",
    "            deleted_dbs.append(cellid)\n",
    "    else:\n",
    "        print('no existing database. making new database')\n",
    "        \n",
    "    reconstruct_db(processing_info_path,landsat_path,sentinel2_path,brdf_path,modified=False)\n",
    "print('restructured dbs:{}'.format(reconstructed_dbs))\n",
    "print('deleted dbs:{}'.format(deleted_dbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77935004",
   "metadata": {},
   "source": [
    "## Check processing db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_db = pd.read_pickle(Path('{}/{:06d}/processing.info'.format(basic_config['raw_dir'],int(basic_config['grid_cell']))))\n",
    "processing_db.tail(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f1dfa",
   "metadata": {},
   "source": [
    "## To create new processing database (if processing.info is corrupted or deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_info_path = Path('{}/{:06d}/processing.info'.format(basic_config['raw_dir'],int(basic_config['grid_cell'])))\n",
    "landsat_path = Path('{}/{:06d}/landsat'.format(basic_config['raw_dir'],int(basic_config['grid_cell'])))\n",
    "sentinel2_path = Path('{}/{:06d}/sentinel2'.format(basic_config['raw_dir'],int(basic_config['grid_cell'])))\n",
    "brdf_path = Path(basic_config['brdf_dir'])\n",
    "modified = False\n",
    "reconstruct_db(processing_info_path,landsat_path,sentinel2_path,brdf_path)\n",
    "processing_db = pd.read_pickle(Path('{}/{:06d}/processing.info'.format(basic_config['raw_dir'],int(basic_config['grid_cell']))))\n",
    "processing_db.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brdf_db = pd.read_pickle(Path(brdf_path/'scene.info'))\n",
    "brdf_db.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa34197",
   "metadata": {},
   "outputs": [],
   "source": [
    "##View processing errors\n",
    "processing_errors1 = processing_db[processing_db['redownload']==True]\n",
    "processing_errors2 = processing_db[~processing_db['brdf_error'].isnull()]\n",
    "processing_errors = pd.concat([processing_errors1, processing_errors2],axis=0)\n",
    "print('of the {} images available, {} were not processed due to errors'.format(processing_db.shape[0],processing_errors.shape[0]))\n",
    "processing_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##View brdf status\n",
    "processed0 = processing_db[processing_db['skip']!=True]\n",
    "processed = processed0[processed0['redownload']!=True]\n",
    "no_brdf = processed[processed['brdf']==False | processed['brdf'].isnull()]\n",
    "print('of the {} images processed, {} do not have brdf calculations'.format(processed.shape[0],no_brdf.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##View coreg status:\n",
    "processed_sentinel = processed[processed.index.str.startswith('S')]\n",
    "creg_sentinel = processed_sentinel[processed_sentinel['coreg']==True]\n",
    "print('of the {} Sentinel images, {} were coreged'.format(processed_sentinel.shape[0],creg_sentinel.shape[0]))\n",
    "avg_x_shift = creg_sentinel['shift_x'].mean()\n",
    "avg_y_shift = creg_sentinel['shift_y'].mean()\n",
    "med_x_shift = creg_sentinel['shift_x'].median()\n",
    "med_y_shift = creg_sentinel['shift_y'].median()\n",
    "print ('shift x: avg:{}, med:{}. shift y: avg:{}, med:{}'.format(avg_x_shift, avg_y_shift, med_x_shift, med_y_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###To get all images in brdf directory:\n",
    "all_images = print_files_in_directory(basic_config['brdf_dir'],'.nc',print_list=basic_config['print_list'],out_dir=basic_config['home_dir'],data_source='stac')\n",
    "\n",
    "if basic_config['print_list'] == True:\n",
    "    print('full dataframe is printed as FileList.txt in {}'.format(out_dir=basic_config['home_dir']))\n",
    "else:\n",
    "    print('sample of dataframe: (Not printed to file. Can print by setting printList=True in notebook_params)')\n",
    "all_images.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ceced8",
   "metadata": {},
   "source": [
    "## Read scene.info file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac118a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "p_df = pd.read_pickle(Path('{}/{:06d}/processing.info'.format(basic_config['raw_dir'],int(basic_config['grid_cell']))))\n",
    "p_df = p_df.reset_index()\n",
    "p_df['sensor'] = p_df.apply(lambda x: x['index'].split('_')[0], axis=1)\n",
    "p_df['shift'] = p_df.apply(lambda x: math.sqrt(math.pow(x['shift_x'],2)+math.pow(x['shift_y'],2)),axis=1)\n",
    "p_df.set_index('index',inplace=True, drop=True)\n",
    "#p_df5 = p_df[p_df['sensor']=='LT05']\n",
    "p_df7 = p_df[p_df['sensor']=='LE07']\n",
    "p_df7.head(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6686ce",
   "metadata": {},
   "source": [
    "# Get cell status from new db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5265583",
   "metadata": {},
   "outputs": [],
   "source": [
    "##for all years:\n",
    "df_all = get_img_list_from_db(basic_config['raw_dir'], basic_config['grid_cell'],basic_config['image_type'],yrs=None,data_source='stac')\n",
    "##for selection of years:\n",
    "df_slice = get_img_list_from_db(basic_config['raw_dir'], basic_config['grid_cell'],basic_config['image_type'],yrs=single_output_params['map_years'],data_source='stac')\n",
    "\n",
    "df_slice.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = get_cell_status(basic_config['raw_dir'], '/home/downspout-cel/paraguay_lc/stac/grids', basic_config['grid_cell'],yrs=None,data_source='stac')\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133acdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_status_db_path = '/home/downspout-cel/paraguay_lc/cell_processing_dl.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_db_path = '/home/downspout-cel/paraguay_lc/cell_processing_post.csv'\n",
    "#update_cell_status_db(status_db_path, range(4050,4101), basic_config['raw_dir'], '/home/downspout-cel/paraguay_lc/stac/grids', yrs=None,data_source='stac')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb38cee",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b26464",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to print output as html\n",
    "outName = str(basic_config['country']+'0_check_and_fill_db_'+str(basic_config['grid_cell']))\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --output=$outName 0_check_and_fill_db.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b2a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
