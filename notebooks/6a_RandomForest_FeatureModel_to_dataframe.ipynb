{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a947286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d48bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in notebook_params notebook, then run that notebook and this cell to update here\n",
    "DO NOT modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "print(\" modelling year is (filter_year): {} (this is first year if season spans two years)\".format(basic_config['filter_yr']))\n",
    "print(\"sample point file is: {}\".format(basic_config['ptfile']))\n",
    "%store -r timeseries_params\n",
    "if timeseries_params['load_samp'] == False:\n",
    "    print('using polygon file to make new point file: {}'.format(basic_config['polyfile']) )\n",
    "    print('will sample {} pts per polygon'.format(timeseries_params['npts']))\n",
    "%store -r classification_params\n",
    "print(\"Classification_Params: \\n\" \n",
    "      \" temp output files are saved to (local_model_dir): {} \\n\" \n",
    "      \" shared modelling files are in (main_model_dir): {} \\n\" \n",
    "      \" feature_model = {} \\n \"\n",
    "      \" feature_model_dict is: {} \\n\"\n",
    "      \" spec_indices = {} \\n si_vars = {} \\n singleton_vars = {} \\n poly_vars = {}\"\n",
    "      .format(classification_params['local_model_dir'],classification_params['main_model_dir'],\n",
    "              classification_params['feature_model'],\n",
    "              classification_params['feature_mod_dict'], \n",
    "              classification_params['spec_indices'],classification_params['si_vars'],classification_params['singleton_vars'],classification_params['poly_vars']\n",
    "              ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6b851",
   "metadata": {},
   "source": [
    "### Check feature model settings\n",
    "##### IF new feature model: Make sure spec_indices, si_vars, singleton_vars and poly_vars are set correctly in parameters (if not, set and rerun above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ee9ff",
   "metadata": {},
   "source": [
    "## Load feature model info (if existing) or save feature model info (if new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod_dict = '../Feature_Models.json'\n",
    "mod_dict = classification_params['feature_mod_dict']\n",
    "spec_indices, si_vars,singleton_vars,poly_vars = getset_variable_model(mod_dict, \n",
    "                      classification_params['feature_model'], \n",
    "                      classification_params['spec_indices'], \n",
    "                      classification_params['si_vars'], \n",
    "                      classification_params['singleton_vars'],\n",
    "                      classification_params['poly_vars']\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd64902",
   "metadata": {},
   "source": [
    "### Make variable dataframe (use all sample points initially -- can then reduce in Notebook 6b)\n",
    "#### Note: This is pretty heavy and should be run from SLURM with bash script (var_data_frame.sh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6257df",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = os.path.join(basic_config['smooth_dir'],'003737')\n",
    "make_variable_stack(in_dir,\n",
    "                    classification_params['feature_model'],\n",
    "                    basic_config['filter_yr'],\n",
    "                    classification_params['spec_indices'],\n",
    "                    classification_params['si_vars'],\n",
    "                    classification_params['feature_mod_dict'],\n",
    "                    classification_params['singleton_vars'] ,\n",
    "                    classification_params['singleton_var_dict'],\n",
    "                    classification_params['poly_vars'], \n",
    "                    classification_params['poly_var_path'], \n",
    "                    None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aef4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "make_var_dataframe(classification_params['local_model_dir'],\n",
    "                  classification_params['spec_indices'],\n",
    "                  classification_params['si_vars'],\n",
    "                  basic_config['smooth_dir'],\n",
    "                  basic_config['grid_file'],\n",
    "                  basic_config['grid_cells'],\n",
    "                  basic_config['polyfile'],\n",
    "                  oldest=timeseries_params['oldest_samp'],\n",
    "                  newest=timeseries_params['newest_samp'],\n",
    "                  npts=timeseries_params['npts'], \n",
    "                  seed=timeseries_params['seed1'],\n",
    "                  load_samp=timeseries_params['load_samp'], \n",
    "                  ptfile=basic_config['ptfile'])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9728b9",
   "metadata": {},
   "source": [
    "## to augment sample with polygon data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f520332",
   "metadata": {},
   "source": [
    "* join sample points to polygon data to get subset of polygons with points (join class info to those polygons)\n",
    "* run make_var_dataframe with load_samp = False and \n",
    "    polygon file set to subset above-- will get {npts} random points from each polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5fe33",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:\n",
    "(these two cells should be last in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "### comment out above line and run this cell to print output as html\n",
    "\n",
    "out_name = str(basic_config['country']+'6a_RandomForest_FeathreModel_to_dataframe'+'_model'+str(classification_params['feature_model'])+str(basic_config['filter_yr']))\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --ExecutePreprocessor.store_widget_state=True --output=$out_name 6b_RandomFoest_ModelComparisons.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
