{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a947286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d48bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from var_dataframe import *\n",
    "from rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in notebook_params notebook, then run that notebook and this cell to update here\n",
    "DO NOT modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "print(\" modelling year is (filter_year): {} (this is first year if season spans two years)\".format(basic_config['filter_yr']))\n",
    "print(\"sample point file is: {}\".format(basic_config['ptfile']))\n",
    "%store -r timeseries_params\n",
    "if timeseries_params['load_samp'] == False:\n",
    "    print('using polygon file to make new point file: {}'.format(basic_config['polyfile']) )\n",
    "    print('will sample {} pts per polygon'.format(timeseries_params['npts']))\n",
    "print('first year of calendar sequence is: {} \\n'.format(timeseries_params['start_mo']))\n",
    "%store -r classification_params\n",
    "print(\"Classification_Params: \\n\" \n",
    "      \" output files are saved to (model_dir): {} \\n\" \n",
    "      \" shared input files are in (main_model_dir): {} \\n\"\n",
    "      \" sample_model = {} \\n feature_model = {} \\n model_name = {} \\n\"\n",
    "      \" the full sample pt file: {} \\n\"\n",
    "      \" the full sample dataframe with the feature model applied: {} \\n\"\n",
    "      \" the subset pt file based on the sample model: {} \\n\"\n",
    "      \" the feature model dictionary: {}\"\n",
    "      .format(classification_params['local_model_dir'],classification_params['main_model_dir'],\n",
    "              classification_params['sample_model'],classification_params['feature_model'],classification_params['model_name'],\n",
    "              basic_config['ptfile'],classification_params['samp_pix_vars'],classification_params['samp_pts'],\n",
    "              classification_params['feature_mod_dict'] \n",
    "              ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6b851",
   "metadata": {},
   "source": [
    "### Check feature model settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c195b5",
   "metadata": {},
   "source": [
    "## See existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec05677",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(classification_params['feature_mod_dict'], 'r+') as feature_model_dict:\n",
    "    dic = json.load(feature_model_dict)\n",
    "    models = pd.DataFrame.from_dict(dic, orient='index')\n",
    "models.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ee9ff",
   "metadata": {},
   "source": [
    "## Load feature model info (if existing) or save feature model info (if new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8d0be",
   "metadata": {},
   "source": [
    "##### IF new feature model: Make sure spec_indices, si_vars, singleton_vars and poly_vars are set correctly in parameters (if not, set and rerun parameters cell above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dict = classification_params['feature_mod_dict']\n",
    "spec_indices,si_vars,spec_indices_pheno,pheno_vars,singleton_vars,poly_vars,combo_bands,band_names = getset_feature_model(\n",
    "                      mod_dict, \n",
    "                      classification_params['feature_model'], \n",
    "                      classification_params['spec_indices'], \n",
    "                      classification_params['si_vars'],\n",
    "                      classification_params['spec_indices_pheno'],\n",
    "                      classification_params['pheno_vars'],\n",
    "                      classification_params['singleton_vars'],\n",
    "                      classification_params['poly_vars']\n",
    ")\n",
    "print('Band names: {}'.format(band_names))                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd64902",
   "metadata": {},
   "source": [
    "## Steps to make variable dataframe -- These steps have already been run - skip to load existing variable dataframe\n",
    "#### Make variable stack for cells with sample data (Note: This is pretty heavy and should be run from SLURM with bash script (rf0_raster_var_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6257df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "make_variable_stack(basic_config['smooth_dir'],\n",
    "                    basic_config['grid_cell'],\n",
    "                    classification_params['feature_model'],\n",
    "                    basic_config['yr_range'][0],\n",
    "                    timeseries_params['start_mo'],\n",
    "                    classification_params['spec_indices'],\n",
    "                    classification_params['si_vars'],\n",
    "                    classification_params['spec_indices_pheno'],\n",
    "                    classification_params['pheno_vars'],\n",
    "                    classification_params['feature_mod_dict'],\n",
    "                    classification_params['singleton_vars'] ,\n",
    "                    classification_params['singleton_var_dict'],\n",
    "                    classification_params['poly_vars'], \n",
    "                    classification_params['poly_var_path'],\n",
    "                    classification_params['combo_bands']\n",
    "                    None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55222aff",
   "metadata": {},
   "source": [
    "### Make variable dataframe (use all sample points initially -- can then reduce in Notebook 6b)(Note: best to run through SLURM with bash script (rf1_var_data_frame.sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aef4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "make_var_dataframe(basic_config['smooth_dir'],\n",
    "                  classification_params['local_model_dir'],\n",
    "                  basic_config['grid_file'],\n",
    "                  basic_config['grid_cells'],\n",
    "                  classification_params['feature_model'],\n",
    "                  classification_params['feature_mod_dict'],\n",
    "                  basic_config['yr_range'][0],\n",
    "                  basic_config['polyfile'],\n",
    "                  oldest=timeseries_params['oldest_samp'],\n",
    "                  newest=timeseries_params['newest_samp'],\n",
    "                  npts=timeseries_params['npts'], \n",
    "                  seed=timeseries_params['seed1'],\n",
    "                  load_samp=timeseries_params['load_samp'], \n",
    "                  ptfile=basic_config['ptfile'])\n",
    "'''\n",
    "\n",
    "# Alternatively, can append new variables to an existing dataframe without stacking them (much less storage required, but\n",
    "# will need to stack final set of variables for surface-level classification)\n",
    "\n",
    "'''\n",
    "append_feature_dataframe(basic_config['smooth_dir'],\n",
    "                         ptfile=basic_config['ptfile'],\n",
    "                         classification_params['samp_pix_vars'],\n",
    "                         basic_config['grid_cells'],\n",
    "                         basic_config['grid_file'],\n",
    "                         classification_params['local_model_dir'],\n",
    "                         basic_config['yr_range'][0],\n",
    "                         timeseries_params['start_mo'],\n",
    "                         classification_params['spec_indices'],\n",
    "                         classification_params['si_vars'],\n",
    "                         classification_params['spec_indices_pheno'],\n",
    "                         classification_params['pheno_vars'],\n",
    "                         classification_params['singleton_vars'] ,\n",
    "                         classification_params['singleton_var_dict'],\n",
    "                         classification_params['poly_vars'], \n",
    "                         classification_params['poly_var_path'],\n",
    "                         classification_params['combo_bands']\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0d3db",
   "metadata": {},
   "source": [
    "## Load existing variable dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a407c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_vars = pd.read_csv(classification_params['samp_pix_vars'])\n",
    "pix_vars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf97d6",
   "metadata": {},
   "source": [
    "## Remove features from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5fce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_mod = 'ptsgdb_Max_nopp_nnweg5-9'\n",
    "drop_indices = [\"nbr\", \"ndmi\", \"wi\", \"evi2\", \"gcvi\"] # to drop all variables for an index (e.g. ['nbr'])\n",
    "drop_vars = [\"May_20\", \"Jun_20\", \"Jul_20\", \"Aug_20\", \"Sept_20\"]  # to drop all instances of a given variable (e.g. [`cv_yr`, 'Jun_20'])\n",
    "drop_combo = ['var_poly_pred_ext', 'var_poly_pred_dst', 'var_poly_pred_area', 'var_poly_pred_APR', 'var_poly_NovDecGCVI_Std'] # to drop specific index_variable combinations (e.g. ['var_wi_Jan_20', 'var_gcvi_maxv_wet'])\n",
    "\n",
    "#classification_params['samp_pix_vars'] = '/home/downspout-cel/paraguay_lc/vector/ptsgdb_{}.csv'.format(new_feature_mod)\n",
    "new_feature_mod = 'Max_dropTest2'\n",
    "drop_indices = [] # to drop all variables for an index (e.g. ['nbr'])\n",
    "drop_vars = ['Jun_20','Jul_20','Aug_20']  # to drop all instances of a given variable (e.g. [`cv_yr`, 'Jun_20'])\n",
    "drop_combo = [] # to drop specific index_variable combinations (e.g. ['var_wi_Jan_20', 'var_gcvi_maxv_wet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_variable_dataframe(classification_params['samp_pix_vars'], \n",
    "                          drop_indices, \n",
    "                          drop_vars, \n",
    "                          drop_combo, \n",
    "                          classification_params['local_model_dir'], \n",
    "                          new_feature_mod,  \n",
    "                          classification_params['feature_mod_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9728b9",
   "metadata": {},
   "source": [
    "## to augment sample with polygon data: (KW TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f520332",
   "metadata": {},
   "source": [
    "* join sample points to polygon data to get subset of polygons with points (join class info to those polygons)\n",
    "* run make_var_dataframe with load_samp = False and \n",
    "    polygon file set to subset above-- will get {npts} random points from each polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5fe33",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:\n",
    "(these two cells should be last in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "### comment out above line and run this cell to print output as html\n",
    "\n",
    "out_name = str(basic_config['country']+'6a_RandomForest_FeathreModel_to_dataframe'+'_model'+str(classification_params['feature_model'])+str(basic_config['filter_yr']))\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --ExecutePreprocessor.store_widget_state=True --output=$out_name 6b_RandomFoest_ModelComparisons.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
