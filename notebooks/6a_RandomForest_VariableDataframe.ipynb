{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a947286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d48bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in notebook_params notebook, then run that notebook and this cell to update here\n",
    "DO NOT modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "print(\"Basic Parameters: \\n brdf_dir = {} \\n gridCell = {} \\n index_dir = {} \\n home_dir = {}\"\n",
    "      .format(basic_config['brdf_dir'],basic_config['grid_cell'],basic_config['index_dir'],basic_config['home_dir']))\n",
    "%store -r classification_params\n",
    "print(\"Classification_Params: \\n model_type = {} \\n samp_pt_file = {} \\n pix_vars = {} \\n pixdf = {} \\n model_name = {} \\n lc_class = {} \\n ranhold = {} \\n impmeth = {}\".format(classification_params['model_type'],classification_params['samp_pts'],classification_params['pix_vars'],classification_params['pixdf'],classification_params['model_name'],\n",
    "classification_params['lc_mod'],classification_params['ranhold'],classification_params['impmeth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut=pd.read_csv('../Class_LUT.csv')\n",
    "lut.drop(['Description'], axis=1, inplace=True)\n",
    "print(lut.sort_values('LC_UNQ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2658d",
   "metadata": {},
   "source": [
    "## start with default models with pixel-only data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_pts = pd.read_csv(classification_params['samp_pts'])\n",
    "pix_vars = pd.read_csv(classification_params['pix_vars'])\n",
    "\n",
    "pix_data = pix_vars.merge(samp_pts, left_on='OID_', right_on='OID_', how='left')\n",
    "\n",
    "pix_data.drop(['LC2'], axis=1, inplace=True)\n",
    "pixdf = pix_data.merge(lut, left_on='Class', right_on='USE_NAME', how='left')\n",
    "print('sample breakdown by LC17 class:')\n",
    "print(pixdf['LC17_name'].value_counts())\n",
    "\n",
    "print('default rf model with all sample pixels and pixel only data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe361c",
   "metadata": {},
   "source": [
    "## prep pixel datasets by reducing sample\n",
    "### First by sampling method (reducing dominant CAN soy pts)\n",
    "### can also do by field size, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model_name = pixdf_25Soy\n",
    "##   removes 3/4 of the soy points because they are far overrepresented\n",
    "pixdf_25Soy = pixdf[(pixdf['rand']>.9) | (pixdf['SampMethod'] != 'CAN - unverified in GE')]\n",
    "print('25Soy sample breakdown by LC17 class:')\n",
    "print(pixdf_25Soy['LC17_name'].value_counts())\n",
    "pixdf_path = os.path.join(classification_params['model_dir'],'pixdf_25Soy.csv')\n",
    "pd.DataFrame.to_csv(pixdf_25Soy, pixdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b423a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model_name = pixdf_lessSoy\n",
    "# removes all soy points that sre not verified in Google Earth\n",
    "pixdf_lessSoy = pixdf_25Soy[pixdf_25Soy['SampMethod'] != 'CAN - unverified in GE']\n",
    "print('there are now {} pts in the training set after dropping CAN soy'.format(len(pixdf_lessSoy)))\n",
    "print('LessSoy sample breakdown by LC17 class:')\n",
    "print(pixdf_lessSoy['LC17_name'].value_counts())\n",
    "pixdf_path = os.path.join(classification_params['model_dir'],'pixdf_lessSoy.csv')\n",
    "pd.DataFrame.to_csv(pixdf_lessSoy, pixdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247eb48",
   "metadata": {},
   "source": [
    "## if polygons are available, can combine pixel and polygon dfs and create rf datasets for points with polygons and those without:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_data = pd.read_csv(classification_params['samp_poly'])\n",
    "#rename column names that also occur in pixel df\n",
    "poly_data.rename(columns={'area':'areaSeg'}, inplace=True)\n",
    "all_data = pixdf.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "polypixdf_path = os.path.join(classification_params['model_dir'],'pts_polyData_joinCheck.csv')\n",
    "pd.DataFrame.to_csv(all_data, polypixdf_path, sep=',', na_rep='NaN', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad21203",
   "metadata": {},
   "source": [
    "### first create dataset for points outside of polygons (here we have no variables to add to the original model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "outsideSeg = all_data[all_data['areaSeg'].isna()]\n",
    "print(f'of the {all_data.shape[0]} sample points in our dataset, {outsideSeg.shape[0]} are outside of our segmented polygons')\n",
    "print(outsideSeg['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'outside')\n",
    "rfout17 = rf_model(outsideSeg,out_dir,'All','Permutation',29,'Fullsamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ef9f7",
   "metadata": {},
   "source": [
    "And for model with more balanced soy representation (25Soy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_25Soy = pixdf_25Soy.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "outsideSeg_25Soy = all_data_25Soy[all_data_25Soy['areaSeg'].isna()]\n",
    "print(outsideSeg_25Soy['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'outside')\n",
    "rfout17_lessSoy = rf_model(outsideSeg_lessSoy,out_dir,'All','Permutation',29,'LessSoy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af312b5",
   "metadata": {},
   "source": [
    "#### now create dataset for points inside of polygons (here we want to add some variables first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135283bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly_data['AvgU'] = poly_data.apply(lambda x:count([x[c] for c in df.columns if c.endswith('U')]),axis=1)\n",
    "#TODO: calculate these in pandas as above\n",
    "poly_data.rename(columns={'areaSeg':'var_areaSeg','AVGU':'var_AVGU','AVGR':'var_AVGR','AVGSTD':'var_AVGSTD','MAXR':'var_MAXR','MINR':'var_MINR','STDU':'var_STDU','MINU':'var_MINU','MAXU':'var_MAXU','rU':'var_RU'}, inplace=True)\n",
    "polyvars = pixdf.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "withinSeg = polyvars[polyvars['var_areaSeg'] > 0]\n",
    "\n",
    "print(withinSeg['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'within')\n",
    "#rfin17 = rf_model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_lessSoy = pixdf_lessSoy.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "withinSeg_lessSoy = all_data_lessSoy[all_data_lessSoy['var_areaSeg']>0]\n",
    "print(withinSeg_lessSoy['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'within')\n",
    "#rfin17_lessSoy = rf_model(..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5fe33",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:\n",
    "(these two cells should be last in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "### comment out above line and run this cell to print output as html\n",
    "\n",
    "out_name = str(basic_config['country']+'6a_RandomFoest_VariableDataframe'+'_model'+str(classification_params['model_name'])+'_'+'Tests1')\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --ExecutePreprocessor.store_widget_state=True --output=$out_name 6b_RandomFoest_ModelComparisons.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
