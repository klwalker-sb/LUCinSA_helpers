{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a947286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d48bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../LUCinSA_helpers\")\n",
    "from rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS: modify in notebook_params notebook, then run that notebook and this cell to update here\n",
    "DO NOT modify this cell\n",
    "'''\n",
    "\n",
    "%store -r basic_config\n",
    "#print(\" modelling year is (filter_year param): {} (this is first year if season spans two years)\".format(basic_config['filter_yr']))\n",
    "%store -r classification_params\n",
    "print(\"Classification_Params: \\n\" \n",
    "      \" temp output files are saved to (local_model_dir): {} \\n\" \n",
    "      \" shared modelling files are in (main_model_dir): {} \\n\" \n",
    "      \" feature_model = {} \\n sample_model = {} \\n model_name = {} \\n\"\n",
    "      \" sample_model_dict is: {} \\n\"\n",
    "      \" samp_pt_file = {} \\n pix_vars = {} \\n pixdf = {} \\n lc_class = {}\"\n",
    "      .format(classification_params['local_model_dir'],classification_params['main_model_dir'],\n",
    "              classification_params['feature_model'],classification_params['sample_model'],classification_params['model_name'],\n",
    "              classification_params['sample_mod_dict'],\n",
    "              classification_params['samp_pts'],classification_params['samp_pix_vars'],classification_params['pixdf'],\n",
    "              classification_params['lc_mod']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ee9ff",
   "metadata": {},
   "source": [
    "## Load feature model info (if existing) or save feature model info (if new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod_dict = '../Feature_Models.json'\n",
    "mod_dict = os.path.join(classification_params['main_model_dir'],'Feature_Models.json')\n",
    "spec_indices, si_vars,singleton_vars = getset_variable_model(mod_dict, \\\n",
    "                      classification_params['feature_model'], \\\n",
    "                      classification_params['spec_indices'], \\\n",
    "                      classification_params['si_vars'], \\\n",
    "                      classification_params['singleton_vars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316a25d",
   "metadata": {},
   "source": [
    "#### test: make stack for new model (this just tests for 1 cell. rf_model / rf_classification methods do this intrenally)\n",
    "####    note: this (and rf_classification) needs all SI variables in sub-stacks. For that, need to run RF_vars for each cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = os.path.join(basic_config['smooth_dir'],'{:06d}'.format(basic_config['grid_cell']),'comp')\n",
    "poly_vars = None\n",
    "make_variable_stack(in_dir,spec_indices,si_vars,singleton_vars,poly_vars,classification_params['feature_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878c7cf",
   "metadata": {},
   "source": [
    "## define / alter sample pixels to participate in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb25ba",
   "metadata": {},
   "source": [
    "### load in LUT to see class options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut=pd.read_csv('../Class_LUT.csv')\n",
    "print(lut.sort_values('LC_UNQ')[['LC_UNQ','USE_NAME','LC25','LC25_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0d401",
   "metadata": {},
   "source": [
    "### start with default models with pixel-only data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_pts = pd.read_csv(classification_params['samp_pts'])\n",
    "pix_vars = pd.read_csv(classification_params['samp_pix_vars'])\n",
    "\n",
    "pix_data = pix_vars.merge(samp_pts, left_on='OID_', right_on='OID_', how='left')\n",
    "\n",
    "pix_data.drop(['LC2'], axis=1, inplace=True)\n",
    "pixdf = pix_data.merge(lut, left_on='Class', right_on='USE_NAME', how='left')\n",
    "print('sample breakdown by LC25 class:')\n",
    "print(pixdf['LC25_name'].value_counts())\n",
    "\n",
    "print('default rf model with all sample pixels and pixel only data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d111a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropClass = ['Crops-Vineyard','NewPlant']\n",
    "pixdf = pixdf[~pixdf['LC17_name'].isin(dropClass)]\n",
    "print(pixdf['LC17_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe361c",
   "metadata": {},
   "source": [
    "## prep pixel datasets by reducing sample\n",
    "### First by sampling method (reducing dominant CAN soy pts)\n",
    "### can also do by field size, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model_name = pixdf_25Soy\n",
    "##   removes 3/4 of the soy points because they are far overrepresented\n",
    "pixdf_25Soy = pixdf[(pixdf['rand']>.9) | (pixdf['SampMethod'] != 'CAN - unverified in GE')]\n",
    "print('25Soy sample breakdown by LC17 class:')\n",
    "print(pixdf_25Soy['LC17_name'].value_counts())\n",
    "pixdf_path = os.path.join(classification_params['model_dir'],'pixdf_25Soy.csv')\n",
    "#pd.DataFrame.to_csv(pixdf_25Soy, pixdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e5e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b423a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model_name = pixdf_lessSoy\n",
    "# removes all soy points that sre not verified in Google Earth\n",
    "pixdf_lessSoy = pixdf[pixdf['SampMethod'] != 'CAN - unverified in GE']\n",
    "print('there are now {} pts in the training set after dropping CAN soy'.format(len(pixdf_lessSoy)))\n",
    "print('LessSoy sample breakdown by LC17 class:')\n",
    "print(pixdf_lessSoy['LC17_name'].value_counts())\n",
    "pixdf_path = os.path.join(classification_params['model_dir'],'pixdf_lessSoy_Nov.csv')\n",
    "#pd.DataFrame.to_csv(pixdf_lessSoy, pixdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027898d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model_name = pixdf_bal1000\n",
    "pixdf1 = pixdf[(pixdf['PurePixel'] != 'No') | (pixdf['LC17_name'].str.contains('mix', na=False, case=False))]\n",
    "pixdf2 = pixdf1[(pixdf['rand']>.84) | (pixdf['SampMethod'] != 'CAN - unverified in GE')]\n",
    "pixdf3 = pixdf2[(pixdf2['rand']>.65) | (pixdf2['LC17_name'] != 'Mixed-VegEdge')]\n",
    "pixdf4 = pixdf3[(pixdf3['rand']>.65) | (pixdf3['LC17_name'] != 'Crops-mix')]\n",
    "pixdf5 = pixdf4[(pixdf4['rand']>.86) | (pixdf4['LC17_name'] != 'Mixed-path')]\n",
    "pixdf6 = pixdf5[(pixdf5['rand']>.50) | (pixdf5['LC17_name'] != 'Crops-Yerba-Mate')]\n",
    "pixdf7 = pixdf6[(pixdf6['rand']>.37) | (pixdf6['LC17_name'] != 'Grassland-Managed')]\n",
    "pixdf8 = pixdf7[(pixdf7['rand']>.36) | (pixdf7['LC17_name'] != 'Trees-Forest')]\n",
    "print('pixdf_bal0 sample breakdown by LC17 class:')\n",
    "print(pixdf8['LC17_name'].value_counts())\n",
    "pixdf_path = os.path.join(classification_params['model_dir'],'pixdf_base1000.csv')\n",
    "pd.DataFrame.to_csv(pixdf5, pixdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### example ###########################\n",
    "#pixdf = pixdf[(pixdf['rand']>.5) | (pixdf['LC17_name'] != 'Mixed-VegEdge')]]\n",
    "#print(pixdf['LC17_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247eb48",
   "metadata": {},
   "source": [
    "## if polygons are available, can combine pixel and polygon dfs and create rf datasets for points with polygons and those without:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_data = pd.read_csv(classification_params['samp_poly'])\n",
    "#rename column names that also occur in pixel df\n",
    "poly_data.rename(columns={'area':'areaSeg'}, inplace=True)\n",
    "all_data = pixdf.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "polypixdf_path = os.path.join(classification_params['model_dir'],'pts_polyData_joinCheck.csv')\n",
    "pd.DataFrame.to_csv(all_data, polypixdf_path, sep=',', na_rep='NaN', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad21203",
   "metadata": {},
   "source": [
    "### first create dataset for points outside of polygons (here we have no variables to add to the original model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "outsideSeg = all_data[all_data['areaSeg'].isna()]\n",
    "print(f'of the {all_data.shape[0]} sample points in our dataset, {outsideSeg.shape[0]} are outside of our segmented polygons')\n",
    "print(outsideSeg['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'outside')\n",
    "rfout17 = rf_model(outsideSeg,out_dir,'All','Permutation',29,'Fullsamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ef9f7",
   "metadata": {},
   "source": [
    "And for model with more balanced soy representation (25Soy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_25Soy = pixdf_25Soy.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "outsideSeg_25Soy = all_data_25Soy[all_data_25Soy['areaSeg'].isna()]\n",
    "print(outsideSeg_25Soy['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'outside')\n",
    "rfout17_lessSoy = rf_model(outsideSeg_lessSoy,out_dir,'All','Permutation',29,'LessSoy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af312b5",
   "metadata": {},
   "source": [
    "#### now create dataset for points inside of polygons (here we want to add some variables first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135283bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly_data['AvgU'] = poly_data.apply(lambda x:count([x[c] for c in df.columns if c.endswith('U')]),axis=1)\n",
    "#TODO: calculate these in pandas as above\n",
    "poly_data.rename(columns={'areaSeg':'var_areaSeg','AVGU':'var_AVGU','AVGR':'var_AVGR','AVGSTD':'var_AVGSTD','MAXR':'var_MAXR','MINR':'var_MINR','STDU':'var_STDU','MINU':'var_MINU','MAXU':'var_MAXU','rU':'var_RU'}, inplace=True)\n",
    "polyvars = pixdf.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "withinSeg = polyvars[polyvars['var_areaSeg'] > 0]\n",
    "\n",
    "print(withinSeg['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'within')\n",
    "#rfin17 = rf_model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_lessSoy = pixdf_lessSoy.merge(poly_data, left_on='OID_', right_on='OID_', how='left')\n",
    "withinSeg_lessSoy = all_data_lessSoy[all_data_lessSoy['var_areaSeg']>0]\n",
    "print(withinSeg_lessSoy['LC17_name'].value_counts())\n",
    "out_dir = os.path.join(classification_params['model_dir'],'within')\n",
    "#rfin17_lessSoy = rf_model(..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5fe33",
   "metadata": {},
   "source": [
    "## To save an html copy of this notebook with all outputs:\n",
    "(these two cells should be last in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "### comment out above line and run this cell to print output as html\n",
    "\n",
    "out_name = str(basic_config['country']+'6a_RandomFoest_VariableDataframe'+'_model'+str(classification_params['model_name'])+'_'+'Tests1')\n",
    "!jupyter nbconvert --output-dir='./Outputs' --to html --no-input --ExecutePreprocessor.store_widget_state=True --output=$out_name 6b_RandomFoest_ModelComparisons.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
